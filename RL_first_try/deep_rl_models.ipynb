{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_rl_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0sZ1e3tsJRd"
      },
      "source": [
        "from stable_baselines import GAIL, SAC\n",
        "from stable_baselines import ACER\n",
        "from stable_baselines import PPO2\n",
        "from stable_baselines import A2C\n",
        "from stable_baselines import DDPG\n",
        "from stable_baselines import TD3\n",
        "\n",
        "from stable_baselines.ddpg.policies import DDPGPolicy\n",
        "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, MlpLnLstmPolicy\n",
        "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "\n",
        "def train_A2C(env_train, model_name, timesteps=25000):\n",
        "    \"\"\"A2C model\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    model = A2C('MlpPolicy', env_train, verbose=0)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{model_name}\")\n",
        "    print('Training time (A2C): ', (end - start) / 60, ' minutes')\n",
        "    return model\n",
        "\n",
        "def train_ACER(env_train, model_name, timesteps=25000):\n",
        "    start = time.time()\n",
        "    model = ACER('MlpPolicy', env_train, verbose=0)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"./{model_name}\")\n",
        "    print('Training time (A2C): ', (end - start) / 60, ' minutes')\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_DDPG(env_train, model_name, timesteps=10000):\n",
        "    \"\"\"DDPG model\"\"\"\n",
        "\n",
        "    # add the noise objects for DDPG\n",
        "    n_actions = env_train.action_space.shape[-1]\n",
        "    param_noise = None\n",
        "    action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
        "\n",
        "    start = time.time()\n",
        "    model = DDPG('MlpPolicy', env_train, param_noise=param_noise, action_noise=action_noise)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"./{model_name}\")\n",
        "    print('Training time (DDPG): ', (end-start)/60,' minutes')\n",
        "    return model\n",
        "\n",
        "def train_PPO(env_train, model_name, timesteps=50000):\n",
        "    \"\"\"PPO model\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    model = PPO2('MlpPolicy', env_train, ent_coef = 0.005, nminibatches = 8)\n",
        "    #model = PPO2('MlpPolicy', env_train, ent_coef = 0.005)\n",
        "\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"./{model_name}\")\n",
        "    print('Training time (PPO): ', (end - start) / 60, ' minutes')\n",
        "    return model\n",
        "\n",
        "def train_GAIL(env_train, model_name, timesteps=1000):\n",
        "    \"\"\"GAIL Model\"\"\"\n",
        "    from stable_baselines.gail import ExportDataset, generate_expert_traj\n",
        "    start = time.time()\n",
        "    # generate expert trajectories\n",
        "    model = SAC('MLpPolicy', env_train, verbose=1)\n",
        "    generate_expert_traj(model, 'expert_model_gail', n_timesteps=100, n_episodes=10)\n",
        "\n",
        "    # Load dataset\n",
        "    dataset = ExpertDataset(expert_path='expert_model_gail.npz', traj_limitation=10, verbose=1)\n",
        "    model = GAIL('MLpPolicy', env_train, dataset, verbose=1)\n",
        "\n",
        "    model.learn(total_timesteps=1000)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"./{model_name}\")\n",
        "    print('Training time (PPO): ', (end - start) / 60, ' minutes')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}